{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5295a35f-9043-47ec-8a71-926802303a06",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Guía práctica: Creación y configuración de clusters (Compute) en Databricks – AWS\n",
    "**Fecha de preparación:** 2025-10-16\n",
    "\n",
    "Este notebook explica los campos y decisiones al crear un **cluster (compute)** en Databricks sobre AWS, incluye ejemplos prácticos, casos de uso y una **configuración recomendada para el curso**.\n",
    "\n",
    "---\n",
    "## Objetivos\n",
    "- Entender cada parámetro del formulario **Create new compute**.\n",
    "- Conocer tipos de clúster (All-purpose vs Job, Single node vs Multi-node) y modos de acceso.\n",
    "- Aplicar buenas prácticas de rendimiento, seguridad y costos.\n",
    "- Verificar la configuración desde código (Spark/Python/SQL).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0421b1e8-8bc0-4a20-a56a-23a602594dbc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Conceptos esenciales\n",
    "**Compute / Cluster**: Conjunto de instancias gestionadas por Databricks para ejecutar notebooks y jobs.\n",
    "\n",
    "**All-purpose cluster**: Para desarrollo interactivo en notebooks; varios usuarios pueden adjuntarse.\n",
    "\n",
    "**Job cluster**: Se crea/derriba por ejecución de un Job; aislamiento y control de costos.\n",
    "\n",
    "**Single node**: Un solo nodo (driver); útil para desarrollo ligero, bibliotecas de Python o pequeños datasets.\n",
    "\n",
    "**Multi-node**: Un driver + N workers para procesamiento distribuido.\n",
    "\n",
    "**Databricks Runtime (DBR)**: Imagen preconfigurada con Spark, Delta y librerías. Puede ser **LTS** (soporte extendido) o con componentes de ML.\n",
    "\n",
    "**Photon**: Motor vectorizado que acelera cargas SQL y Delta Lake.\n",
    "\n",
    "**Autoscaling**: Ajusta dinámicamente el número de workers entre un mínimo y un máximo.\n",
    "\n",
    "**Auto-termination**: Apaga el clúster tras N minutos de inactividad para ahorrar costos.\n",
    "\n",
    "**Unity Catalog (Access mode)**: Gobierno centralizado de datos y permisos a nivel de objeto.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "251f2a42-3bb2-401f-b442-f965029a75aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Campos del formulario \"Create new compute\" y su significado\n",
    "1. **Compute name**: Nombre descriptivo (conviene incluir propósito y entorno, p. ej. `course-dev-ap`).\n",
    "2. **Policy**: Plantilla que restringe/estandariza opciones (si el admin la define). Para el curso, suele ser `Unrestricted`.\n",
    "3. **Machine learning**: Habilita runtimes con librerías de ML preinstaladas (scikit-learn, MLlib extra, etc.). Útil si entrenará modelos en el notebook.\n",
    "4. **Databricks runtime**: Versión del DBR. Preferir **LTS** estable. Opcional: *Photon acceleration* para SQL/Delta.\n",
    "5. **Worker type**: Tipo/tamaño de instancia de AWS para los workers (CPU, memoria, red). Seleccione equilibrado.\n",
    "6. **Min / Max**: Rango de autoscaling. Para cargas pequeñas, mantenga valores modestos.\n",
    "7. **Single node**: Forzar clúster de un solo nodo (driver). Útil para desarrollo/local libraries.\n",
    "8. **Enable autoscaling**: Marca para activar escalado automático.\n",
    "9. **Terminate after**: Minutos de inactividad antes de apagar (control de costos).\n",
    "10. **Advanced performance**: Opciones adicionales del runtime (Delta caching, etc.) según versión.\n",
    "11. **Tags**: Etiquetas de costo/propiedad (clave-valor) propagadas a AWS.\n",
    "12. **Access mode** (Unity Catalog): `Auto` o `Manual` para determinar modo de acceso y aislamiento UC.\n",
    "13. **Instance profile**: Rol/credencial de IAM para acceder a S3 u otros servicios (si requiere datos externos).\n",
    "14. **Spark** (config): Clave-valor para *tuning* (p. ej., `spark.sql.shuffle.partitions`).\n",
    "15. **SSH**: Habilitar acceso SSH al driver (solo si es necesario y permitido por seguridad).\n",
    "16. **Logging**: Envío de logs a S3/DBFS para auditoría.\n",
    "17. **Init scripts**: Scripts de inicialización para instalar dependencias o configurar el entorno.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ed02e1a9-b3a0-43ee-b855-c1f1584178dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Modos de acceso y Unity Catalog\n",
    "- **Auto/UC**: Aísla identidades y permisos por usuario/tablas; recomendado si su workspace usa Unity Catalog.\n",
    "- **Shared/Single User/No Isolation** (según disponibilidad de la versión): definen el aislamiento de credenciales y cómo se resuelven permisos de datos.\n",
    "Para el curso, use **Access mode: Auto** salvo que requiera un modo específico por políticas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "98781f00-adea-4c08-9395-08d637fdd863",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Tipos de clúster y casos de uso\n",
    "### All-purpose vs Job\n",
    "- **All-purpose**: Desarrollo colaborativo, EDA, pruebas iterativas.\n",
    "- **Job**: Producción/orquestación con Workflows; crea/termina por ejecución, cost-efficient y reproducible.\n",
    "\n",
    "### Single node vs Multi-node\n",
    "- **Single node**: Notebooks de utilería, bibliotecas Python, datasets pequeños (< 2–5 GB) o pruebas rápidas.\n",
    "- **Multi-node**: ETL distribuidas, uniones/agrupaciones grandes, entrenamiento ML distribuido.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fe4cc988-25a1-4024-92f9-1069b88bdf78",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Buenas prácticas de rendimiento\n",
    "- Activar **Photon** en cargas SQL/Delta intensivas.\n",
    "- Ajustar `spark.sql.shuffle.partitions` a un valor acorde al tamaño (p. ej., 64 para datasets pequeños del curso).\n",
    "- Usar **broadcast joins** cuando una tabla < tamaño de broadcast (`spark.sql.autoBroadcastJoinThreshold`).\n",
    "- **Compaction** y **Z-Order** para Delta tras cargas grandes.\n",
    "- **Cache** selectivo (Delta caching / `df.cache()`) cuando haya reutilización de resultados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "12e9a6ad-5e47-4ff2-b108-b1721412a83e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Seguridad y acceso a datos\n",
    "- Preferir **Unity Catalog** para permisos de objetos (catalogs/schemas/tables).\n",
    "- Para acceso a S3, usar **Instance Profiles** o **External Locations**; evitar llaves estáticas.\n",
    "- Principio de **mínimo privilegio** en IAM.\n",
    "- Registrar logs del clúster y auditar accesos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b9cc3739-c33f-49c7-ab66-fb6bcca2bdd3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Costos: recomendaciones\n",
    "- **Auto-termination** entre 30 y 90 minutos en ambientes de entrenamiento.\n",
    "- **Autoscaling** con *Min* bajo y *Max* razonable.\n",
    "- Elegir **instancias equilibradas** (vCPU/memoria) y evitar sobreaprovisionamiento.\n",
    "- Limpiar clústeres inactivos y usar **Job clusters** para pipelines programados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8a994601-4093-440c-8137-203570cb8eea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Configuración recomendada para el curso (AWS Premium Trial)\n",
    "- **Databricks Runtime**: `16.4 LTS` (Spark 3.5.x) con **Photon** habilitado.\n",
    "- **Tipo de clúster**: **All-purpose**, **Multi-node**.\n",
    "- **Worker type**: tamaño equilibrado (por ejemplo, `r5d.xlarge` o el equivalente gestionado por *fleet* con ~4 vCPU y ~32 GB RAM).\n",
    "- **Autoscaling**: **Min 2**, **Max 4** workers.\n",
    "- **Auto-termination**: **60 minutos**.\n",
    "- **Access mode**: **Auto** (Unity Catalog).\n",
    "- **Instance profile**: `None` (a menos que necesite acceso a buckets S3 externos específicos).\n",
    "- **Spark config** (ejemplo):\n",
    "  - `spark.sql.shuffle.partitions=64`\n",
    "  - `spark.databricks.delta.optimizeWrite.enabled=true`\n",
    "  - `spark.databricks.delta.autoCompact.enabled=true`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1d19c8a2-d331-4956-a5db-42982c4e669d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Verificación desde código (ejemplos)\n",
    "Use estas celdas para confirmar versión de Spark, Photon, y parámetros clave del clúster.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c9931481-aef6-4568-a8ab-24ba41087ad1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# TODO: Versión y propiedades básicas de Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6d5d0212-8cfd-4599-95ad-9edc90fa6644",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# TODO: Comprobar configuraciones relevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c73eae82-ebda-4d95-8f00-735e80443b81",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# TODO:  Ajustar particiones de shuffle para el contexto del curso (si no está fijado por política)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a2ea30e0-56cf-414a-9dd7-f65b1f1f558a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### SQL: exploración rápida de catálogos y tablas\n",
    "Ejemplo de consultas que suelen funcionar en workspaces con `samples`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "16df50c7-b845-41e0-aaaa-a7599ff44fda",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Carga de ejemplo (distribuida)\n",
    "La siguiente celda crea un DataFrame de ejemplo y realiza una agregación con *shuffle* para observar el comportamiento del clúster.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "37390a44-6fa0-4ee9-b36f-b5939fc1cf94",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# TODO: Ejemplo de carga distribuida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ac9fb658-3f54-48ec-9246-5f1c14d77a98",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Troubleshooting habitual\n",
    "- **Cluster no arranca**: revisar cuota de instancias en AWS y políticas; intente un tipo de instancia diferente.\n",
    "- **Permisos a datos denegados**: validar Access mode de UC, grants en objetos y/o Instance Profile.\n",
    "- **Jobs lentos**: revisar *shuffle partitions*, tamaño de clúster, Photon y optimizaciones Delta.\n",
    "- **Fallas por librerías**: usar `Init scripts` o *Libraries* del clúster; fijar versiones compatibles.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cfec6788-1a68-4321-85ea-ec8cc409c114",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Conclusiones\n",
    "- Elegir el **runtime LTS** y habilitar **Photon** acelera la mayoría de workloads analíticas.\n",
    "- Diseñar el clúster con **autoscaling** y **auto-termination** controla costos en el trial.\n",
    "- Validar y ajustar parámetros de Spark desde el notebook mejora el rendimiento en datasets pequeños del curso.\n",
    "- Para producción, preferir **Job clusters** orquestados con Workflows y *policies* de clúster.\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "clusters",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

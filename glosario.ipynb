{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eabb9d8d",
   "metadata": {},
   "source": [
    "# Glosario esencial para Databricks en AWS\n",
    "**Fecha de preparación:** 2025-10-16\n",
    "\n",
    "Este glosario reúne términos clave que suelen generar dudas en una primera sesión práctica de Databricks. Cada entrada incluye una **definición breve**, **cuándo usarlo**, su **relación con Databricks/AWS**, y **cosas para recordar**.\n",
    "\n",
    "---\n",
    "## Cómo usar este glosario\n",
    "- Búsqueda rápida durante la clase.\n",
    "- Punto de referencia para documentación y código en el repositorio del curso.\n",
    "- Complemento para las secciones teóricas de Lakehouse, Delta Lake y configuración de clústeres.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ef7763",
   "metadata": {},
   "source": [
    "## Índice rápido\n",
    "- [Apache Spark](#Apache-Spark)\n",
    "- [Data Lake](#Data-Lake)\n",
    "- [Data Warehouse](#Data-Warehouse)\n",
    "- [Lakehouse](#Lakehouse)\n",
    "- [Delta Lake](#Delta-Lake)\n",
    "- [Delta Table (Tabla Delta)](#Delta-Table-(Tabla-Delta))\n",
    "- [Time Travel](#Time-Travel)\n",
    "- [Z-Order](#Z-Order)\n",
    "- [Compaction](#Compaction)\n",
    "- [S3 (Amazon Simple Storage Service)](#S3-(Amazon-Simple-Storage-Service))\n",
    "- [IAM (AWS Identity and Access Management)](#IAM-(AWS-Identity-and-Access-Management))\n",
    "- [Glue Catalog](#Glue-Catalog)\n",
    "- [JDBC](#JDBC)\n",
    "- [ACID](#ACID)\n",
    "- [ERP/CRM](#ERP/CRM)\n",
    "- [SQL](#SQL)\n",
    "- [Scala](#Scala)\n",
    "- [R](#R)\n",
    "- [Python](#Python)\n",
    "- [DBFS (Databricks File System)](#DBFS-(Databricks-File-System))\n",
    "- [Databricks SQL](#Databricks-SQL)\n",
    "- [Compute / Cluster](#Compute-/-Cluster)\n",
    "- [Workflows (Jobs)](#Workflows-(Jobs))\n",
    "- [Repos (GitHub)](#Repos-(GitHub))\n",
    "- [Structured Streaming](#Structured-Streaming)\n",
    "- [Parquet](#Parquet)\n",
    "- [Schema-on-read / Schema-on-write](#Schema-on-read-/-Schema-on-write)\n",
    "- [Medallion Architecture (Bronze/Silver/Gold)](#Medallion-Architecture-(Bronze/Silver/Gold))\n",
    "- [Unity Catalog / Catálogo](#Unity-Catalog-/-Catálogo)\n",
    "- [External Location](#External-Location)\n",
    "- [Credential Passthrough](#Credential-Passthrough)\n",
    "- [MLflow](#MLflow)\n",
    "- [Cost Optimization (Optimización de costos)](#Cost-Optimization-(Optimización-de-costos))\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71823d70",
   "metadata": {},
   "source": [
    "## Apache Spark\n",
    "**Definición:** Motor de procesamiento distribuido para grandes volúmenes de datos. Proporciona APIs en Python, SQL, Scala y R para ejecutar transformaciones y acciones sobre clústeres.\n",
    "\n",
    "**Cuándo usarlo:** Procesamiento batch y streaming, ETL a escala, ML distribuido.\n",
    "\n",
    "**Relación con Databricks/AWS:** Databricks ofrece runtimes optimizados de Spark y notebooks colaborativos.\n",
    "\n",
    "**Cosas para recordar**\n",
    "- Transformaciones se ejecutan *lazy* (evaluación diferida).\n",
    "- Persistencia y particionamiento impactan el rendimiento.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fce080",
   "metadata": {},
   "source": [
    "## Data Lake\n",
    "**Definición:** Almacén de datos en bruto (estructurados, semiestructurados y no estructurados) generalmente en almacenamiento de objetos.\n",
    "\n",
    "**Cuándo usarlo:** Ingesta masiva, staging, exploración y ciencia de datos.\n",
    "\n",
    "**Relación con Databricks/AWS:** En AWS suele implementarse sobre Amazon S3; Databricks lo usa como capa de almacenamiento base.\n",
    "\n",
    "**Cosas para recordar**\n",
    "- Esquema a la lectura (schema-on-read).\n",
    "- Bajo costo y alta escalabilidad.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f532cdb2",
   "metadata": {},
   "source": [
    "## Data Warehouse\n",
    "**Definición:** Repositorio analítico optimizado para consultas, con esquema bien definido (schema-on-write).\n",
    "\n",
    "**Cuándo usarlo:** BI, reporting, métricas establecidas y gobernanza estricta.\n",
    "\n",
    "**Relación con Databricks/AWS:** Lakehouse integra capacidades tipo DW; Databricks SQL habilita consultas interactivas sobre tablas gobernadas.\n",
    "\n",
    "**Cosas para recordar**\n",
    "- Rendimiento alto en consultas y semántica consistente.\n",
    "- Menor flexibilidad que un Data Lake puro.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb89b81b",
   "metadata": {},
   "source": [
    "## Lakehouse\n",
    "**Definición:** Arquitectura que combina la flexibilidad del Data Lake con la gobernanza y rendimiento del Data Warehouse.\n",
    "\n",
    "**Cuándo usarlo:** Unificar analítica y ML sobre la misma fuente gobernada.\n",
    "\n",
    "**Relación con Databricks/AWS:** Databricks implementa Lakehouse apoyándose en Delta Lake sobre S3.\n",
    "\n",
    "**Cosas para recordar**\n",
    "- Evita silos y duplicidad de pipelines.\n",
    "- Tablas con transacciones ACID y time travel.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b7aed2",
   "metadata": {},
   "source": [
    "## Delta Lake\n",
    "**Definición:** Formato/estructura de tablas sobre almacenamiento de objetos que aporta transacciones ACID, versionado y optimizaciones.\n",
    "\n",
    "**Cuándo usarlo:** Tablas confiables para BI y ML sobre el lago.\n",
    "\n",
    "**Relación con Databricks/AWS:** En AWS, archivos en S3 + transaccionalidad administrada por Delta; expone tablas a Databricks SQL.\n",
    "\n",
    "**Cosas para recordar**\n",
    "- `OPTIMIZE`, `VACUUM`, `Z-ORDER`, `GENERATE` para rendimiento y mantenimiento.\n",
    "- Soporta time travel (`VERSION AS OF`, `TIMESTAMP AS OF`).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753cfb1b",
   "metadata": {},
   "source": [
    "## Delta Table (Tabla Delta)\n",
    "**Definición:** Tabla basada en Delta Lake con metadatos y *transaction log* que garantizan integridad.\n",
    "\n",
    "**Cuándo usarlo:** Persistencia confiable de datos transformados (Bronze/Silver/Gold).\n",
    "\n",
    "**Relación con Databricks/AWS:** Consultables vía Spark DataFrames y Databricks SQL.\n",
    "\n",
    "**Cosas para recordar**\n",
    "- Permite *MERGE INTO*, *DELETE*, *UPDATE* atómicos.\n",
    "- Versionado y auditoría integrados.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3e535a",
   "metadata": {},
   "source": [
    "## Time Travel\n",
    "**Definición:** Capacidad de consultar versiones históricas de una tabla Delta.\n",
    "\n",
    "**Cuándo usarlo:** Auditoría, depuración, reproducibilidad de informes/experimentos.\n",
    "\n",
    "**Relación con Databricks/AWS:** Usable con SQL y PySpark en Databricks.\n",
    "\n",
    "**Cosas para recordar**\n",
    "- Cuidado con políticas de `VACUUM` que eliminan archivos antiguos.\n",
    "- Excelente para trazabilidad.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e66e90",
   "metadata": {},
   "source": [
    "## Z-Order\n",
    "**Definición:** Técnica de *data skipping* que mejora el pruning en columnas frecuentemente filtradas.\n",
    "\n",
    "**Cuándo usarlo:** Optimizar consultas con filtros selectivos.\n",
    "\n",
    "**Relación con Databricks/AWS:** Comando `OPTIMIZE ... ZORDER BY (col)`.\n",
    "\n",
    "**Cosas para recordar**\n",
    "- No sustituye un particionado bien diseñado.\n",
    "- Aplicar tras cargas grandes o compactación.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4de48b",
   "metadata": {},
   "source": [
    "## Compaction\n",
    "**Definición:** Proceso de combinar muchos archivos pequeños en menos archivos grandes para mejorar el rendimiento.\n",
    "\n",
    "**Cuándo usarlo:** After ingestiones incrementales/streaming que generan archivos pequeños.\n",
    "\n",
    "**Relación con Databricks/AWS:** `OPTIMIZE` en Delta realiza compactación controlada.\n",
    "\n",
    "**Cosas para recordar**\n",
    "- Mejora el throughput de lectura.\n",
    "- Coordinar con ventanas de carga.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80edaa64",
   "metadata": {},
   "source": [
    "## S3 (Amazon Simple Storage Service)\n",
    "**Definición:** Servicio de almacenamiento de objetos altamente duradero y escalable.\n",
    "\n",
    "**Cuándo usarlo:** Capa de datos para Data Lake y tablas Delta.\n",
    "\n",
    "**Relación con Databricks/AWS:** Databricks lee/escribe en buckets S3 (rutas `s3://...` o montajes/External Locations).\n",
    "\n",
    "**Cosas para recordar**\n",
    "- Control de acceso mediante IAM o *bucket policies*.\n",
    "- Costos por almacenamiento y *requests*.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94eacce",
   "metadata": {},
   "source": [
    "## IAM (AWS Identity and Access Management)\n",
    "**Definición:** Servicio para administrar identidades, roles y permisos en AWS.\n",
    "\n",
    "**Cuándo usarlo:** Conceder acceso a S3, Glue, etc. desde clústeres/notebooks.\n",
    "\n",
    "**Relación con Databricks/AWS:** Databricks se integra vía roles, *instance profiles* o credenciales temporales.\n",
    "\n",
    "**Cosas para recordar**\n",
    "- Principio de mínimo privilegio.\n",
    "- Rotación de credenciales y auditoría.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c250e5",
   "metadata": {},
   "source": [
    "## Glue Catalog\n",
    "**Definición:** Catálogo de metadatos administrado por AWS Glue que describe bases, tablas y esquemas.\n",
    "\n",
    "**Cuándo usarlo:** Descubrimiento de datos, *data governance* ligera, integración con servicios AWS.\n",
    "\n",
    "**Relación con Databricks/AWS:** Databricks puede leer/escribir tablas registradas en Glue como catálogo externo.\n",
    "\n",
    "**Cosas para recordar**\n",
    "- Consistencia de esquemas facilita interoperabilidad.\n",
    "- Gestionar *crawlers* y permisos.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198f8577",
   "metadata": {},
   "source": [
    "## JDBC\n",
    "**Definición:** Protocolo estándar para conectarse a bases de datos relacionales.\n",
    "\n",
    "**Cuándo usarlo:** Ingesta/egesta desde/ hacia RDBMS (MySQL, Postgres, SQL Server, etc.).\n",
    "\n",
    "**Relación con Databricks/AWS:** Databricks usa conectores Spark JDBC para lectura/escritura distribuida.\n",
    "\n",
    "**Cosas para recordar**\n",
    "- Ajustar `numPartitions`, `fetchsize` y *pushdown* para rendimiento.\n",
    "- Cuidar transferencias y límites de origen.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6df0cb1",
   "metadata": {},
   "source": [
    "## ACID\n",
    "**Definición:** Conjunto de propiedades de transacciones: Atomicidad, Consistencia, Aislamiento y Durabilidad.\n",
    "\n",
    "**Cuándo usarlo:** Garantizar integridad en escrituras concurrentes y fallas.\n",
    "\n",
    "**Relación con Databricks/AWS:** Delta Lake implementa ACID sobre S3 para tablas del Lakehouse.\n",
    "\n",
    "**Cosas para recordar**\n",
    "- Evita lecturas sucias y estados intermedios.\n",
    "- Base para operaciones `MERGE/UPDATE/DELETE`.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4a95f1",
   "metadata": {},
   "source": [
    "## ERP/CRM\n",
    "**Definición:** Sistemas empresariales para gestión de recursos (ERP) y relación con clientes (CRM).\n",
    "\n",
    "**Cuándo usarlo:** Fuentes frecuentes de datos maestros y transaccionales.\n",
    "\n",
    "**Relación con Databricks/AWS:** Ingeridos hacia el Lakehouse mediante conectores, CDC o exportaciones batch.\n",
    "\n",
    "**Cosas para recordar**\n",
    "- Atender *PII* y cumplimiento (privacidad).\n",
    "- Estandarizar *keys* y catálogos maestros.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5eef4bd",
   "metadata": {},
   "source": [
    "## SQL\n",
    "**Definición:** Lenguaje estándar para consulta y manipulación de datos.\n",
    "\n",
    "**Cuándo usarlo:** BI, reporting, data quality y transformaciones declarativas.\n",
    "\n",
    "**Relación con Databricks/AWS:** Databricks SQL ejecuta consultas sobre tablas Delta y crea visualizaciones/dashboards.\n",
    "\n",
    "**Cosas para recordar**\n",
    "- Optimizar con índices lógicos (Z-Order), partición y *statistics*.\n",
    "- Preferir operaciones set-based.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bc2b5d",
   "metadata": {},
   "source": [
    "## Scala\n",
    "**Definición:** Lenguaje en la JVM, tipado estático, base original de la API de Spark.\n",
    "\n",
    "**Cuándo usarlo:** Desarrollos de alto rendimiento y librerías del ecosistema Spark.\n",
    "\n",
    "**Relación con Databricks/AWS:** Totalmente compatible con Spark en Databricks.\n",
    "\n",
    "**Cosas para recordar**\n",
    "- Excelente para *type-safety* y rendimiento.\n",
    "- Curva de aprendizaje mayor que Python.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22604715",
   "metadata": {},
   "source": [
    "## R\n",
    "**Definición:** Lenguaje para estadística y análisis.\n",
    "\n",
    "**Cuándo usarlo:** Modelado, visualización y reportes específicos.\n",
    "\n",
    "**Relación con Databricks/AWS:** Databricks soporta notebooks en R y SparkR.\n",
    "\n",
    "**Cosas para recordar**\n",
    "- Menor uso en ingeniería de datos distribuida.\n",
    "- Útil para análisis exploratorio y modelos.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02223d60",
   "metadata": {},
   "source": [
    "## Python\n",
    "**Definición:** Lenguaje de propósito general, muy usado en ciencia/ingeniería de datos.\n",
    "\n",
    "**Cuándo usarlo:** ETL con PySpark, ML con scikit-learn/MLlib, orquestaciones ligeras.\n",
    "\n",
    "**Relación con Databricks/AWS:** Lenguaje por defecto en muchos notebooks de Databricks.\n",
    "\n",
    "**Cosas para recordar**\n",
    "- Ecosistema rico de librerías.\n",
    "- Cuidar *UDF* vs. funciones nativas Spark.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e09ffd",
   "metadata": {},
   "source": [
    "## DBFS (Databricks File System)\n",
    "**Definición:** Abstracción de sistema de archivos en Databricks que expone almacenamiento (incluido S3).\n",
    "\n",
    "**Cuándo usarlo:** Acceso sencillo a rutas de datos (`/dbfs/...`).\n",
    "\n",
    "**Relación con Databricks/AWS:** Usado para staging y lectura/escritura local en clúster.\n",
    "\n",
    "**Cosas para recordar**\n",
    "- Diferenciar *driver* vs. *worker* paths.\n",
    "- Preferir rutas S3/External Locations para datos persistentes.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c525e18",
   "metadata": {},
   "source": [
    "## Databricks SQL\n",
    "**Definición:** Módulo de Databricks para consultas SQL interactivas, *endpoints* y dashboards.\n",
    "\n",
    "**Cuándo usarlo:** Autoservicio de BI y análisis ad-hoc.\n",
    "\n",
    "**Relación con Databricks/AWS:** Consulta directa de tablas Delta en el Lakehouse.\n",
    "\n",
    "**Cosas para recordar**\n",
    "- Permite *visualizations* y *parameterized queries*.\n",
    "- Integra control de acceso por objetos.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921afae2",
   "metadata": {},
   "source": [
    "## Compute / Cluster\n",
    "**Definición:** Conjunto de máquinas gestionadas por Databricks para ejecutar notebooks y jobs.\n",
    "\n",
    "**Cuándo usarlo:** Procesar workloads batch/streaming/ML.\n",
    "\n",
    "**Relación con Databricks/AWS:** Autoscaling y *auto-termination* para controlar costos.\n",
    "\n",
    "**Cosas para recordar**\n",
    "- Elegir tamaño y *runtime* adecuados.\n",
    "- Políticas de clúster para gobierno.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87009650",
   "metadata": {},
   "source": [
    "## Workflows (Jobs)\n",
    "**Definición:** Orquestación y programación de notebooks, tareas y dependencias.\n",
    "\n",
    "**Cuándo usarlo:** Automatizar pipelines y activar alertas.\n",
    "\n",
    "**Relación con Databricks/AWS:** Ejecución confiable con *task clusters* o *all-purpose clusters*.\n",
    "\n",
    "**Cosas para recordar**\n",
    "- Definir *retries*, *timeouts* y notificaciones.\n",
    "- Separar dev/test/prod.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da2e27c",
   "metadata": {},
   "source": [
    "## Repos (GitHub)\n",
    "**Definición:** Integración con Git para versionar notebooks y código.\n",
    "\n",
    "**Cuándo usarlo:** Colaboración, *branches*, *pull requests* y CI.\n",
    "\n",
    "**Relación con Databricks/AWS:** Sincroniza el Workspace con repositorios remotos.\n",
    "\n",
    "**Cosas para recordar**\n",
    "- Estandarizar estructura del repo.\n",
    "- Usar *nbdime* u otras herramientas para *diff* de notebooks.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17557cf",
   "metadata": {},
   "source": [
    "## Structured Streaming\n",
    "**Definición:** API de Spark para procesamiento incremental con semántica declarativa.\n",
    "\n",
    "**Cuándo usarlo:** Eventos, IoT, logs y CDC.\n",
    "\n",
    "**Relación con Databricks/AWS:** Escritura en tablas Delta con transacciones y *checkpointing*.\n",
    "\n",
    "**Cosas para recordar**\n",
    "- Definir *trigger* y *output mode* adecuados.\n",
    "- Diseñar *watermarks* para late data.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12724b14",
   "metadata": {},
   "source": [
    "## Parquet\n",
    "**Definición:** Formato de archivo columnar comprimido y eficiente.\n",
    "\n",
    "**Cuándo usarlo:** Almacenamiento intermedio y *data exchange* eficiente.\n",
    "\n",
    "**Relación con Databricks/AWS:** Base de muchas optimizaciones de Spark y Delta.\n",
    "\n",
    "**Cosas para recordar**\n",
    "- Soporta *predicate pushdown*.\n",
    "- Estructura columnar mejora la compresión.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba44a13",
   "metadata": {},
   "source": [
    "## Schema-on-read / Schema-on-write\n",
    "**Definición:** Modelo de aplicar el esquema al leer (DL) o al escribir (DW).\n",
    "\n",
    "**Cuándo usarlo:** Equilibrar flexibilidad vs. gobernanza.\n",
    "\n",
    "**Relación con Databricks/AWS:** Lakehouse permite ambos según la capa (Bronze/Silver/Gold).\n",
    "\n",
    "**Cosas para recordar**\n",
    "- Definir contratos de datos en Silver/Gold.\n",
    "- Validaciones y *expectations* son clave.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e56ee94",
   "metadata": {},
   "source": [
    "## Medallion Architecture (Bronze/Silver/Gold)\n",
    "**Definición:** Patrón de capas: Bronze (raw), Silver (limpieza/estandarización), Gold (modelos analíticos).\n",
    "\n",
    "**Cuándo usarlo:** Organizar pipelines claros y auditables.\n",
    "\n",
    "**Relación con Databricks/AWS:** Implementable con tablas Delta y Jobs.\n",
    "\n",
    "**Cosas para recordar**\n",
    "- Facilita *lineage* y control de calidad.\n",
    "- Simplifica consumo por BI/ML.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2b48a7",
   "metadata": {},
   "source": [
    "## Unity Catalog / Catálogo\n",
    "**Definición:** Gobierno centralizado de datos, permisos a nivel de objetos y *lineage*.\n",
    "\n",
    "**Cuándo usarlo:** Seguridad y cumplimiento a escala multi-workspace.\n",
    "\n",
    "**Relación con Databricks/AWS:** Gestiona catálogos, esquemas y tablas para Databricks SQL y Spark.\n",
    "\n",
    "**Cosas para recordar**\n",
    "- Separar dominios por catálogo/esquema.\n",
    "- Aplicar *row/column-level security* donde aplique.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98ca627",
   "metadata": {},
   "source": [
    "## External Location\n",
    "**Definición:** Recurso gobernado que mapea ubicaciones de almacenamiento (S3) con control de acceso.\n",
    "\n",
    "**Cuándo usarlo:** Lectura/escritura segura de datos externos al workspace.\n",
    "\n",
    "**Relación con Databricks/AWS:** Base para crear *volumes* y tablas externas en Lakehouse.\n",
    "\n",
    "**Cosas para recordar**\n",
    "- Usar roles IAM dedicados.\n",
    "- Auditar accesos.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62c6465",
   "metadata": {},
   "source": [
    "## Credential Passthrough\n",
    "**Definición:** Mecanismo para que el usuario acceda a datos con sus credenciales temporales.\n",
    "\n",
    "**Cuándo usarlo:** Cumplimiento y auditoría por usuario.\n",
    "\n",
    "**Relación con Databricks/AWS:** Disponible según integración Databricks-AWS.\n",
    "\n",
    "**Cosas para recordar**\n",
    "- Evita *shared keys*.\n",
    "- Requiere configuración específica del workspace.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c112ed19",
   "metadata": {},
   "source": [
    "## MLflow\n",
    "**Definición:** Plataforma para seguimiento de experimentos, gestión de artefactos y registro/versionado de modelos.\n",
    "\n",
    "**Cuándo usarlo:** Comparar runs, reproducir experimentos y servir modelos.\n",
    "\n",
    "**Relación con Databricks/AWS:** Integrado en Databricks con *Tracking Server* y *Model Registry*.\n",
    "\n",
    "**Cosas para recordar**\n",
    "- Etiquetar parámetros y métricas clave.\n",
    "- Promover modelos por *stages*: Staging/Production.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff53cd4e",
   "metadata": {},
   "source": [
    "## Cost Optimization (Optimización de costos)\n",
    "**Definición:** Conjunto de prácticas para reducir gasto en cómputo y almacenamiento.\n",
    "\n",
    "**Cuándo usarlo:** Control operacional del trial y entornos productivos.\n",
    "\n",
    "**Relación con Databricks/AWS:** Autoscaling, auto-termination, *spot instances* (si procede) y mantenimiento de tablas.\n",
    "\n",
    "**Cosas para recordar**\n",
    "- Borrar clústeres ociosos.\n",
    "- Compactar y *vacuum* para evitar *storage bloat*.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abb3f57",
   "metadata": {},
   "source": [
    "## Nota final\n",
    "Este glosario es un documento vivo. Añade términos específicos de tu organización (nombres de dominios de datos, sistemas legados, políticas internas) y vincula ejemplos de notebooks del repositorio para acelerar el onboarding del equipo."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
